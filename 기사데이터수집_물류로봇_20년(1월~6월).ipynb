{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ohmyprogram/Delivery-Robot-TextMining/blob/main/%EA%B8%B0%EC%82%AC%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%89%E1%85%AE%E1%84%8C%E1%85%B5%E1%86%B8_%E1%84%86%E1%85%AE%E1%86%AF%E1%84%85%E1%85%B2%E1%84%85%E1%85%A9%E1%84%87%E1%85%A9%E1%86%BA_20%E1%84%82%E1%85%A7%E1%86%AB(1%E1%84%8B%E1%85%AF%E1%86%AF~6%E1%84%8B%E1%85%AF%E1%86%AF).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2173add",
      "metadata": {
        "id": "d2173add"
      },
      "source": [
        "## 1. 기본 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c05a847",
      "metadata": {
        "id": "0c05a847"
      },
      "source": [
        "### 1-1. Selenium 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf6c3b5",
      "metadata": {
        "id": "3cf6c3b5",
        "outputId": "f7b1c4c8-cd9d-4520-c68a-43d9673478ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.7.2-py3-none-any.whl (6.3 MB)\n",
            "     ---------------------------------------- 6.3/6.3 MB 9.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
            "Collecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "     -------------------------------------- 384.9/384.9 kB 5.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting exceptiongroup>=1.0.0rc9\n",
            "  Downloading exceptiongroup-1.0.4-py3-none-any.whl (14 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
            "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "     ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
            "Installing collected packages: outcome, h11, exceptiongroup, async-generator, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed async-generator-1.10 exceptiongroup-1.0.4 h11-0.14.0 outcome-1.2.0 selenium-4.7.2 trio-0.22.0 trio-websocket-0.9.2 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "# 가상의 브라우저를 컨트롤 할 수 있도록 도와주는 selenium 패키지를 설치합니다.\n",
        "# 아래 주석을 해지하고 셀을 실행합니다.\n",
        "# 설치는 한번만 수행하면 되며, 재설치시 Requirement already satisfied: ~ 라는 메시지가 출력됩니다.\n",
        "\n",
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5199a15",
      "metadata": {
        "id": "e5199a15"
      },
      "source": [
        "### 1-2. 라이브러리 Import 및 Chrome Driver 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc9675e",
      "metadata": {
        "id": "ddc9675e"
      },
      "outputs": [],
      "source": [
        "# Python 코드를 통해 가상의 브라우저를 띄우기 위해 selenium 패키지를 import 합니다.\n",
        "import selenium\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "\n",
        "# selenium을 활용해 브라우저를 직접 띄우는 경우, 실제 웹서핑을 할때처럼 로딩시간이 필요합니다.\n",
        "# 로딩시간 동안 대기하도록 코드를 구성하기위해 time 패키지를 import 합니다.\n",
        "import time\n",
        "\n",
        "# Python 코드를 통해 웹페이지에 정보를 요청하기 위해 BeautifulSoup, urllib 패키지를 import 합니다.\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cbdfd66",
      "metadata": {
        "id": "5cbdfd66"
      },
      "outputs": [],
      "source": [
        "# Chrome Driver를 호출합니다.\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "\n",
        "# 브라우저에 임의로 User-agent 옵션을 넣어 Python 코드로 접속함을 숨깁니다.\n",
        "chrome_options.add_argument('--user-agent=\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36\"')\n",
        "\n",
        "# Chrome Driver 파일의 경로를 지정하고 실행합니다.\n",
        "# Chrome Driver는 아래 링크에서 다운로드 가능합니다.\n",
        "# 본 Jupyter Notebook 파일과 동일한 경로에 Chrome Driver가 존재하는 경우 아래 경로를 그대로 사용합니다.\n",
        "\n",
        "#service = Service(\"./chromedriver\")    # Windows 운영체제\n",
        "service = Service(\"chromedriver.exe\")      # MAC, Linux 운영체제\n",
        "                                       # 경고메시지 출력시 조치 : [시스템 환경설정] > [보안 및 개인정보 보호] > \"Chrome Drive ~ 확인없이 허용\"\n",
        "\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f48b956e",
      "metadata": {
        "id": "f48b956e"
      },
      "source": [
        "## 2. 뉴스기사 및 댓글 수집하기\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adde6d8a",
      "metadata": {
        "id": "adde6d8a"
      },
      "source": [
        "### 2-1. 뉴스기사 정보 입력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef89f16",
      "metadata": {
        "id": "4ef89f16"
      },
      "outputs": [],
      "source": [
        "# 수집할 뉴스기사 정보를 입력합니다.\n",
        "QUERY = \"로봇 +물류\"          # 필터링 키워드\n",
        "START_DATE = \"2020.01.01\" # 필터링 일자 (작성일 기준)\n",
        "END_DATE = \"2020.06.30\"\n",
        "START_PAGE = 1            # 검색결과 저장 페이지 범위 (네이버 뉴스기사는 검색결과 중 최대 4,000페이지만 제공)\n",
        "END_PAGE = 400\n",
        "                          # 기사와 댓글을 저장할 파일명\n",
        "article_filename = \"article_\" + QUERY + \"_\" + START_DATE + \"_\" + END_DATE + \"_\" + str(START_PAGE) + \".txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da22568d",
      "metadata": {
        "id": "da22568d"
      },
      "source": [
        "### 2-2. 뉴스기사 수집"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec0e9b5",
      "metadata": {
        "id": "8ec0e9b5",
        "outputId": "b3beb233-a79e-462c-cb40-891f6ef2f627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400/400 Page, [강세 토픽] 면세점 테마, JTC +2.49%, 신세계 +2.42%                                                NA 한줄뉴스>\n",
            "* 최대 4000 개 기사 수집이 완료되었습니다.\n",
            "* 수집된 기사는 아래 파일에 저장되었습니다.\n",
            "  : article_로봇 +물류_2020.01.01_2020.06.30_1.txt\n"
          ]
        }
      ],
      "source": [
        "f = open(article_filename, \"w\", encoding=\"utf-8\")\n",
        "news_count = 0\n",
        "\n",
        "for page in range(START_PAGE, END_PAGE*10+1, 10):\n",
        "\n",
        "\n",
        "    URL = \"https://search.naver.com/search.naver?&where=news&query=\" + QUERY\n",
        "    URL += \"&sm=tab_pge&sort=0&photo=0&field=0&reporter_article=&pd=3&ds=\"\n",
        "    URL += START_DATE + \"&de=\" + END_DATE + \"&docid=&&start=\" + str(page) + \"&refresh_start=0\"\n",
        "    driver.get(URL)\n",
        "    time.sleep(1)\n",
        "\n",
        "    # 검색결과 리스트 불러오기\n",
        "    try:\n",
        "        news_list = driver.find_element(By.CLASS_NAME, \"list_news\").find_elements(By.CLASS_NAME, \"bx\") # 검색결과 리스트 중 기사 목록\n",
        "    except:\n",
        "        break\n",
        "\n",
        "    # 수집 카운트 업데이트\n",
        "    news_count += len(news_list)\n",
        "\n",
        "    # 검색결과 기사 하나씩 탐색\n",
        "    for news in news_list[:]:\n",
        "        link_list = news.find_element(By.CLASS_NAME, \"info_group\").find_elements(By.TAG_NAME, \"a\")\n",
        "        if len(link_list) <= 1:\n",
        "            continue\n",
        "        # 기사 URL 새탭으로 이동\n",
        "\n",
        "        article_url = link_list[1].get_attribute(\"href\").strip()\n",
        "        link_list[1].click()\n",
        "        time.sleep(1)\n",
        "        current_window = driver.current_window_handle\n",
        "        try:\n",
        "            new_window = [window for window in driver.window_handles if window != current_window][0]\n",
        "            driver.switch_to.window(new_window)\n",
        "        except:\n",
        "            driver.switch_to.window(current_window)\n",
        "            continue\n",
        "        time.sleep(1)\n",
        "\n",
        "        try:\n",
        "            # 언론사, 작성일자, 본문, 제목을 기사 유형별 방법으로 수집\n",
        "            if \"sports.news\" in article_url:\n",
        "                source_label = driver.find_element(By.ID, \"pressLogo\").find_element(By.TAG_NAME, \"img\")\n",
        "                source = source_label.get_attribute(\"alt\").strip()\n",
        "                datetime = driver.find_element(By.CLASS_NAME, \"info\").find_element(By.TAG_NAME, \"span\").text.replace(\"기사입력\", \"\").strip()\n",
        "                content = driver.find_element(By.CLASS_NAME, \"news_end\").text.strip().replace(\"\\n\", \" \")\n",
        "                title = driver.find_element(By.CLASS_NAME, \"title\").text.strip()\n",
        "            elif \"n.news\" in article_url:\n",
        "                try:\n",
        "                    try:\n",
        "                        source_label = driver.find_element(By.ID, \"pressLogo\").find_element(By.TAG_NAME, \"img\")\n",
        "                        source = source_label.get_attribute(\"alt\").strip()\n",
        "                    except:\n",
        "                        source_label = driver.find_element(By.CLASS_NAME, \"media_end_head_top_logo\").find_element(By.TAG_NAME, \"img\")\n",
        "                        source = source_label.get_attribute(\"alt\").strip()\n",
        "                    datetime = driver.find_element(By.CLASS_NAME, \"_ARTICLE_DATE_TIME\").text.strip()\n",
        "                    content = driver.find_element(By.CLASS_NAME, \"_article_content\").text.strip().replace(\"\\n\", \" \")\n",
        "                    title = driver.find_element(By.CLASS_NAME, \"media_end_head_headline\").text.strip()\n",
        "                except:\n",
        "                    source_label = driver.find_element(By.CLASS_NAME, \"press_logo\")\n",
        "                    source_img = source_label.find_element(By.TAG_NAME, \"img\")\n",
        "                    source = source_img.get_attribute(\"alt\").strip()\n",
        "                    datetime = driver.find_element(By.CLASS_NAME, \"author\")\n",
        "                    datetime = datetime.find_element(By.TAG_NAME, \"em\").text.strip()\n",
        "                    content = driver.find_element(By.ID, \"articeBody\").text.strip().replace(\"\\n\", \" \")\n",
        "                    title = driver.find_element(By.CLASS_NAME, \"end_tit\").text.strip()\n",
        "            # 그 외 기사는 무시\n",
        "            else:\n",
        "                driver.close()\n",
        "                time.sleep(1)\n",
        "                driver.switch_to.window(current_window)\n",
        "                continue\n",
        "\n",
        "            # 댓글(리뷰) 개수\n",
        "#             review_count_list = driver.find_elements(By.CLASS_NAME, \"u_cbox_count\")\n",
        "#             if len(review_count_list) > 0:\n",
        "#                 review_count = review_count_list[0].text.replace(\",\", \"\")\n",
        "#             else:\n",
        "#                 review_count = \"0\"\n",
        "\n",
        "            # 수집결과 출력\n",
        "            print(\" \"*100, end=\"\\r\")\n",
        "            print(str(int(page/10)+1)+\"/\"+str(END_PAGE)+\" Page,\", title, end=\"\\r\")\n",
        "            f.write(source + \"\\t\" + datetime + \"\\t\" +\n",
        "                     article_url + \"\\t\" + title + \"\\t\" + content + \"\\n\")\n",
        "        except:\n",
        "            driver.close()\n",
        "            time.sleep(1)\n",
        "            driver.switch_to.window(current_window)\n",
        "            f.flush()\n",
        "            continue\n",
        "        driver.close()\n",
        "        time.sleep(1)\n",
        "        driver.switch_to.window(current_window)\n",
        "        f.flush()\n",
        "\n",
        "f.close()\n",
        "\n",
        "# 수집종료\n",
        "print()\n",
        "print(\"* 최대\", news_count, \"개 기사 수집이 완료되었습니다.\")\n",
        "print(\"* 수집된 기사는 아래 파일에 저장되었습니다.\")\n",
        "print(\"  :\", article_filename)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}